{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(1)\n",
    "print (\"cargo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def datos():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "    print (\"Dimensiones train\")\n",
    "    print (mnist.train.images.shape)\n",
    "    print (\"Dimensiones test\")\n",
    "    print (mnist.test.images.shape)\n",
    "    print (\"cargo\")\n",
    "    X_train_o = mnist.train.images[:55000,:]\n",
    "    Y_train_o = mnist.train.labels[:55000,:]\n",
    "    X_test_o = mnist.test.images[:10000,:]\n",
    "    Y_test_o = mnist.test.labels[:10000,:]\n",
    "    print (\"Dimensiones X train\")\n",
    "    print (X_train_o.shape)\n",
    "    print (\"Dimensiones Y train\")\n",
    "    print (Y_train_o.shape)\n",
    "    print (\"Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\")\n",
    "    X_train=X_train_o.T\n",
    "    Y_train=Y_train_o.T\n",
    "    print (\"........\")\n",
    "    print (\"X train transpuesto\", str(X_train.shape))\n",
    "    print (\"Y train transpuesto\", str(Y_train.shape))\n",
    "    X_test=X_test_o.T\n",
    "    Y_test=Y_test_o.T\n",
    "    print (\"X test transpuesto\", str(X_test.shape))\n",
    "    print (\"Y test transpuesto\", str(Y_test.shape))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x, None),name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y, None),name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_y):\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 =  tf.get_variable(\"W1\", [25,n_x], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 =  tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 =  tf.get_variable(\"W3\", [n_y,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [n_y,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):   \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                               # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                             # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1000, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    #print (n_x)\n",
    "    #print (m)\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    ### inicializar los parametros y la arquitectura de la red\n",
    "    parameters = initialize_parameters(n_x,n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    ##### Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            #print (\"mini \"+str(num_minibatches))\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "  \n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions, xq no recibe a3. Claro no lo tengo. Â¿como sabe que debe calcularlo?\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        '''\n",
    "        print (\"Train Accuracy:\", sess.run(accuracy, feed_dict ={X: X_train, Y: Y_train})\n",
    "\n",
    "        print (\"Test Accuracy:\", sess.run(accuracy, feed_dict ={X: X_test, Y: Y_test})\n",
    "        \n",
    "        '''\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Dimensiones train\n",
      "(55000, 784)\n",
      "Dimensiones test\n",
      "(10000, 784)\n",
      "cargo\n",
      "Dimensiones X train\n",
      "(55000, 784)\n",
      "Dimensiones Y train\n",
      "(55000, 10)\n",
      "Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\n",
      "........\n",
      "X train transpuesto (784, 55000)\n",
      "Y train transpuesto (10, 55000)\n",
      "X test transpuesto (784, 10000)\n",
      "Y test transpuesto (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.426199\n",
      "Cost after epoch 100: 0.066361\n",
      "Cost after epoch 200: 0.030645\n",
      "Cost after epoch 300: 0.011905\n",
      "Cost after epoch 400: 0.003304\n",
      "Cost after epoch 500: 0.000741\n",
      "Cost after epoch 600: 0.000130\n",
      "Cost after epoch 700: 0.000130\n",
      "Cost after epoch 800: 0.000020\n",
      "Cost after epoch 900: 0.000013\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f978a635400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9559\n",
      "CPU times: user 40min 1s, sys: 2min 7s, total: 42min 8s\n",
      "Wall time: 26min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-685724cd716e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray_r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "array=np.random.randint(55000, size=10)\n",
    "for i in array:\n",
    "    print (i)\n",
    "    print(y_train[i].argmax(axis=0))\n",
    "    image = x_train[i].reshape([28,28])\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "\n",
    "print (image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
