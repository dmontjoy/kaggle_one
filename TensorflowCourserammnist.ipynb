{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(1)\n",
    "print (\"cargo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def datos():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "    print (\"Dimensiones train\")\n",
    "    print (mnist.train.images.shape)\n",
    "    print (\"Dimensiones test\")\n",
    "    print (mnist.test.images.shape)\n",
    "    print (\"cargo\")\n",
    "    X_train_o = mnist.train.images[:55000,:]\n",
    "    Y_train_o = mnist.train.labels[:55000,:]\n",
    "    X_test_o = mnist.test.images[:10000,:]\n",
    "    Y_test_o = mnist.test.labels[:10000,:]\n",
    "    print (\"Dimensiones X train\")\n",
    "    print (X_train_o.shape)\n",
    "    print (\"Dimensiones Y train\")\n",
    "    print (Y_train_o.shape)\n",
    "    print (\"Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\")\n",
    "    X_train=X_train_o.T\n",
    "    Y_train=Y_train_o.T\n",
    "    print (\"........\")\n",
    "    print (\"X train transpuesto\", str(X_train.shape))\n",
    "    print (\"Y train transpuesto\", str(Y_train.shape))\n",
    "    X_test=X_test_o.T\n",
    "    Y_test=Y_test_o.T\n",
    "    print (\"X test transpuesto\", str(X_test.shape))\n",
    "    print (\"Y test transpuesto\", str(Y_test.shape))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x, None),name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y, None),name=\"Y\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_y):\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 =  tf.get_variable(\"W1\", [25,n_x], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 =  tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 =  tf.get_variable(\"W3\", [n_y,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [n_y,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):   \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                               # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                             # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1000, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    #print (n_x)\n",
    "    #print (m)\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    ### inicializar los parametros y la arquitectura de la red\n",
    "    parameters = initialize_parameters(n_x,n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    ##### Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            #print (\"mini \"+str(num_minibatches))\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "  \n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions, xq no recibe a3. Claro no lo tengo. Â¿como sabe que debe calcularlo?\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        '''\n",
    "        print (\"Train Accuracy:\", sess.run(accuracy, feed_dict ={X: X_train, Y: Y_train})\n",
    "\n",
    "        print (\"Test Accuracy:\", sess.run(accuracy, feed_dict ={X: X_test, Y: Y_test})\n",
    "        \n",
    "        '''\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-labels-idx1-ubyte.gz\n",
      "Dimensiones train\n",
      "(55000, 784)\n",
      "Dimensiones test\n",
      "(10000, 784)\n",
      "cargo\n",
      "Dimensiones X train\n",
      "(55000, 784)\n",
      "Dimensiones Y train\n",
      "(55000, 10)\n",
      "Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\n",
      "........\n",
      "X train transpuesto (784, 55000)\n",
      "Y train transpuesto (10, 55000)\n",
      "X test transpuesto (784, 10000)\n",
      "Y test transpuesto (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.426199\n",
      "Cost after epoch 100: 0.066470\n",
      "Cost after epoch 200: 0.030539\n",
      "Cost after epoch 300: 0.011537\n",
      "Cost after epoch 400: 0.003124\n",
      "Cost after epoch 500: 0.000730\n",
      "Cost after epoch 600: 0.000113\n",
      "Cost after epoch 700: 0.000045\n",
      "Cost after epoch 800: 0.000471\n",
      "Cost after epoch 900: 0.000010\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHApmZlbx/wGChp0mjj762QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x348e717ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9563\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-685724cd716e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray_r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "array=np.random.randint(55000, size=10)\n",
    "for i in array:\n",
    "    print (i)\n",
    "    print(y_train[i].argmax(axis=0))\n",
    "    image = x_train[i].reshape([28,28])\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n",
    "    plt.show()\n",
    "\n",
    "print (image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
