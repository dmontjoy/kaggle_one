{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(1)\n",
    "print (\"cargo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def datos():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "    print (\"Dimensiones train\")\n",
    "    print (mnist.train.images.shape)\n",
    "    print (\"Dimensiones test\")\n",
    "    print (mnist.test.images.shape)\n",
    "    print (\"cargo\")\n",
    "    X_train_o = mnist.train.images[:55000,:]\n",
    "    Y_train_o = mnist.train.labels[:55000,:]\n",
    "    X_test_o = mnist.test.images[:10000,:]\n",
    "    Y_test_o = mnist.test.labels[:10000,:]\n",
    "    print (\"Dimensiones X train\")\n",
    "    print (X_train_o.shape)\n",
    "    print (\"Dimensiones Y train\")\n",
    "    print (Y_train_o.shape)\n",
    "    print (\"Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\")\n",
    "    X_train=X_train_o.T\n",
    "    Y_train=Y_train_o.T\n",
    "    print (\"........\")\n",
    "    print (\"X train transpuesto\", str(X_train.shape))\n",
    "    print (\"Y train transpuesto\", str(Y_train.shape))\n",
    "    X_test=X_test_o.T\n",
    "    Y_test=Y_test_o.T\n",
    "    print (\"X test transpuesto\", str(X_test.shape))\n",
    "    print (\"Y test transpuesto\", str(Y_test.shape))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x, None),name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y, None),name=\"Y\")\n",
    "    ### Otras variables ###\n",
    "    \n",
    "     # variable learning rate\n",
    "    lr = tf.placeholder(tf.float32)\n",
    "    # train/test selector for batch normalisation\n",
    "    tst = tf.placeholder(tf.bool)\n",
    "    ##Drop Out\n",
    "    pkeep = tf.placeholder(tf.float32)\n",
    "    # training iteration\n",
    "    #iter = tf.placeholder(tf.int32)   \n",
    "    \n",
    "    return X, Y, tst,pkeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_y):\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 =  tf.get_variable(\"W1\", [25,n_x], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 =  tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 =  tf.get_variable(\"W3\", [n_y,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [n_y,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(Ylogits, is_test):\n",
    "    Ylogits = tf.transpose(Ylogits)\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.999) # adding the iteration prevents from averaging across non-existing iterations\n",
    "    bnepsilon = 1e-5\n",
    "    ##con 0 el calculo es vertical\n",
    "    mean, variance = tf.nn.moments(Ylogits, [0])\n",
    "    \n",
    "    update_moving_averages = exp_moving_avg.apply([mean, variance])\n",
    "    m = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean)\n",
    "    v = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance)\n",
    "    \n",
    "    Ybn = tf.nn.batch_normalization(Ylogits, m, v, None, None, bnepsilon)\n",
    "    Ybn = tf.transpose(Ybn)\n",
    "    return Ybn, update_moving_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters,tst,pkeep):   \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    #Z1 = tf.add(tf.matmul(W1,X),b1)  \n",
    "    Z1 = tf.matmul(W1,X)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    Z1B, update_ema1 = batchnorm(Z1, tst)\n",
    "    \n",
    "    A1 = tf.nn.relu(Z1B)                                              # A1 = relu(Z1)\n",
    "    A1d = tf.nn.dropout(A1, pkeep)\n",
    "    \n",
    "    #Z2 = tf.add(tf.matmul(W2,A1),b2)\n",
    "    \n",
    "    Z2 = tf.matmul(W2,A1d)                                               # Z2 = np.dot(W2, a1) + b2\n",
    "    Z2B, update_ema2 = batchnorm(Z2, tst)\n",
    "    \n",
    "    A2 = tf.nn.relu(Z2B)                                              # A2 = relu(Z2)\n",
    "    A2d = tf.nn.dropout(A2, pkeep)\n",
    "    \n",
    "    Z3 = tf.add(tf.matmul(W3,A2d),b3)                                             # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #update_ema = tf.group(update_ema1)\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 30, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    #print (n_x)\n",
    "    #print (m)\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y,tst, pkeep= create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    ### inicializar los parametros y la arquitectura de la red\n",
    "    parameters = initialize_parameters(n_x,n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters,tst,pkeep)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    ##### Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        i=0\n",
    "        for epoch in range(num_epochs):\n",
    "            i=i+1\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            #print (\"mini \"+str(num_minibatches))\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y, tst: False,pkeep:0.75})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "                #if(i==30):\n",
    "                #    break\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                print (\"epoch\",str(epoch))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "  \n",
    "\n",
    "        # plot the cost\n",
    "        \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions, xq no recibe a3. Claro no lo tengo. ¿como sabe que debe calcularlo?\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train,tst: False,pkeep:0.75}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test,tst: True,pkeep:1}))\n",
    "        '''\n",
    "        print (\"Train Accuracy:\", sess.run(accuracy, feed_dict ={X: X_train, Y: Y_train})\n",
    "\n",
    "        print (\"Test Accuracy:\", sess.run(accuracy, feed_dict ={X: X_test, Y: Y_test})\n",
    "        \n",
    "        '''\n",
    "        print (\"Termino\")\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-labels-idx1-ubyte.gz\n",
      "Dimensiones train\n",
      "(55000, 784)\n",
      "Dimensiones test\n",
      "(10000, 784)\n",
      "cargo\n",
      "Dimensiones X train\n",
      "(55000, 784)\n",
      "Dimensiones Y train\n",
      "(55000, 10)\n",
      "Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\n",
      "........\n",
      "X train transpuesto (784, 55000)\n",
      "Y train transpuesto (10, 55000)\n",
      "X test transpuesto (784, 10000)\n",
      "Y test transpuesto (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.832114\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIzP8HnrXcmGndAfAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xce806e1e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.807873\n",
      "Test Accuracy: 0.8959\n",
      "Termino\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
