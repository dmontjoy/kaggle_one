{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data\\t10k-labels-idx1-ubyte.gz\n",
      "cargo datos\n"
     ]
    }
   ],
   "source": [
    "#No tiene hidden layers\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import math\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import ops\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "X_test=(mnist.test.images).T\n",
    "X_train = (mnist.train.images).T\n",
    "Y_test = (mnist.test.labels).T\n",
    "Y_train = (mnist.train.labels).T\n",
    "#X_test = sess.run(tf.transpose(mnist.test.images))\n",
    "#X_train = sess.run(tf.transpose(mnist.train.images))\n",
    "#Y_test = sess.run(tf.transpose(mnist.test.labels))\n",
    "#Y_train = sess.run(tf.transpose(mnist.train.labels))\n",
    "print (\"cargo datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procesando\n",
      "test\n",
      "0.9163\n",
      "train\n",
      "0.935873\n",
      "termino\n",
      "Wall time: 14min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"procesando\")\n",
    "ops.reset_default_graph()  \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Create the model, no importa el numero de entradas sino el n√∫mero de pixel (28 * 28).\n",
    "X = tf.placeholder(tf.float32, [784,None])\n",
    "# las etiquetas correctas\n",
    "Y = tf.placeholder(tf.float32, [10,None])\n",
    "\n",
    "\n",
    "# inicializo con 0 las variables\n",
    "#W = tf.Variable(tf.zeros([10,784]))\n",
    "W =  tf.get_variable(\"W\", [10,784], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "\n",
    "b = tf.Variable(tf.zeros([10,1]))\n",
    "\n",
    "# predicciones\n",
    "Z3 = tf.matmul(W,X) + b\n",
    "\n",
    "## cross entropy, es una formula con variables. y_ and  y, cost\n",
    "#cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels= y_, logits=y))\n",
    "cost = compute_cost(Z3,Y)\n",
    "## train step, optimazer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(cost)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "# Traindataset = tf.data.Dataset.range(100)\n",
    "#for _ in range(1000):\n",
    "#    batch_xs, batch_ys = mnist.train.next_batch(100)    \n",
    "#    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "for epoch in range(1000):\n",
    "    minibatches=random_mini_batches(X_train, Y_train, 64, seed = 0)\n",
    "    for minibatch in minibatches:\n",
    "        (minibatch_X, minibatch_Y) = minibatch\n",
    "        _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                     \n",
    "correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print (\"test\")\n",
    "print(sess.run(accuracy, feed_dict={X: X_test, Y: Y_test}))\n",
    "print (\"train\")\n",
    "print(sess.run(accuracy, feed_dict={X: X_train, Y: Y_train}))\n",
    "sess.close()\n",
    "\n",
    "print (\"termino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "   \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    #print (\"random m\")\n",
    "    #print (X.shape)\n",
    "    #print (m)\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    #print (permutation)\n",
    "    #print (\"fin permu\")\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "permutation = list(np.random.permutation(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 9, 3, 1, 8, 4, 0, 6, 5]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def da_random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "   \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    print (\"random m\")\n",
    "    print (X.shape)\n",
    "    print (m)\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    print (permutation)\n",
    "    print (\"fin permu\")\n",
    "    shuffled_X = X[:, permutation]\n",
    "\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print (sess.run(tf.transpose(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
