{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargo\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(1)\n",
    "print (\"cargo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def datos():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "    print (\"Dimensiones train\")\n",
    "    print (mnist.train.images.shape)\n",
    "    print (\"Dimensiones test\")\n",
    "    print (mnist.test.images.shape)\n",
    "    print (\"cargo\")\n",
    "    X_train_o = mnist.train.images[:55000,:]\n",
    "    Y_train_o = mnist.train.labels[:55000,:]\n",
    "    X_test_o = mnist.test.images[:10000,:]\n",
    "    Y_test_o = mnist.test.labels[:10000,:]\n",
    "    print (\"Dimensiones X train\")\n",
    "    print (X_train_o.shape)\n",
    "    print (\"Dimensiones Y train\")\n",
    "    print (Y_train_o.shape)\n",
    "    print (\"Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\")\n",
    "    X_train=X_train_o.T\n",
    "    Y_train=Y_train_o.T\n",
    "    print (\"........\")\n",
    "    print (\"X train transpuesto\", str(X_train.shape))\n",
    "    print (\"Y train transpuesto\", str(Y_train.shape))\n",
    "    X_test=X_test_o.T\n",
    "    Y_test=Y_test_o.T\n",
    "    print (\"X test transpuesto\", str(X_test.shape))\n",
    "    print (\"Y test transpuesto\", str(Y_test.shape))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x, None),name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y, None),name=\"Y\")\n",
    "    ### Otras variables ###\n",
    "    \n",
    "     # variable learning rate\n",
    "    lr = tf.placeholder(tf.float32)\n",
    "    # train/test selector for batch normalisation\n",
    "    tst = tf.placeholder(tf.bool)\n",
    "    # training iteration\n",
    "    #iter = tf.placeholder(tf.int32)   \n",
    "    \n",
    "    return X, Y, tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_y):\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 =  tf.get_variable(\"W1\", [25,n_x], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 =  tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 =  tf.get_variable(\"W3\", [n_y,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [n_y,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(Ylogits, is_test):\n",
    "    Ylogits = tf.transpose(Ylogits)\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.999) # adding the iteration prevents from averaging across non-existing iterations\n",
    "    bnepsilon = 1e-5\n",
    "    \n",
    "    mean, variance = tf.nn.moments(Ylogits, [0])\n",
    "    \n",
    "    update_moving_averages = exp_moving_avg.apply([mean, variance])\n",
    "    m = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean)\n",
    "    v = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance)\n",
    "    \n",
    "    Ybn = tf.nn.batch_normalization(Ylogits, m, v, None, None, bnepsilon)\n",
    "    Ybn = tf.transpose(Ybn)\n",
    "    return Ybn, update_moving_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters,tst):   \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    #Z1 = tf.add(tf.matmul(W1,X),b1)  \n",
    "    Z1 = tf.matmul(W1,X)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    Z1B, update_ema1 = batchnorm(Z1, tst)\n",
    "    \n",
    "    A1 = tf.nn.relu(Z1B)                                              # A1 = relu(Z1)\n",
    "    \n",
    "    #Z2 = tf.add(tf.matmul(W2,A1),b2)\n",
    "    \n",
    "    Z2 = tf.matmul(W2,A1)                                               # Z2 = np.dot(W2, a1) + b2\n",
    "    Z2B, update_ema2 = batchnorm(Z2, tst)\n",
    "    \n",
    "    A2 = tf.nn.relu(Z2B)                                              # A2 = relu(Z2)\n",
    "    \n",
    "    \n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                             # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    #update_ema = tf.group(update_ema1)\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "def compute_cost(Z3, Y):\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1000, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    #print (n_x)\n",
    "    #print (m)\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y,tst= create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    ### inicializar los parametros y la arquitectura de la red\n",
    "    parameters = initialize_parameters(n_x,n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters,tst)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    ##### Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        i=0\n",
    "        for epoch in range(num_epochs):\n",
    "            i=i+1\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            #print (\"mini \"+str(num_minibatches))\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y, tst: False})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "                #if(i==30):\n",
    "                #    break\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "  \n",
    "\n",
    "        # plot the cost\n",
    "        \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions, xq no recibe a3. Claro no lo tengo. ¿como sabe que debe calcularlo?\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train,tst: False}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test,tst: True}))\n",
    "        '''\n",
    "        print (\"Train Accuracy:\", sess.run(accuracy, feed_dict ={X: X_train, Y: Y_train})\n",
    "\n",
    "        print (\"Test Accuracy:\", sess.run(accuracy, feed_dict ={X: X_test, Y: Y_test})\n",
    "        \n",
    "        '''\n",
    "        print (\"Termino\")\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Dimensiones train\n",
      "(55000, 784)\n",
      "Dimensiones test\n",
      "(10000, 784)\n",
      "cargo\n",
      "Dimensiones X train\n",
      "(55000, 784)\n",
      "Dimensiones Y train\n",
      "(55000, 10)\n",
      "Las dimensiones de X son Nx por M, donde Nx son las caracteristicas y M es el numero, por eso hay que trasponerlo\n",
      "........\n",
      "X train transpuesto (784, 55000)\n",
      "Y train transpuesto (10, 55000)\n",
      "X test transpuesto (784, 10000)\n",
      "Y test transpuesto (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test = datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.549897\n",
      "Cost after epoch 100: 0.103190\n",
      "Cost after epoch 200: 0.080752\n",
      "Cost after epoch 300: 0.070439\n",
      "Cost after epoch 400: 0.065263\n",
      "Cost after epoch 500: 0.062289\n",
      "Cost after epoch 600: 0.062641\n",
      "Cost after epoch 700: 0.059469\n",
      "Cost after epoch 800: 0.059070\n",
      "Cost after epoch 900: 0.056447\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nScHMzGY4KZiZ2Yz/D6sEMWkeA9YXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2d1484c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.997782\n",
      "Test Accuracy: 0.6259\n",
      "Termino\n",
      "CPU times: user 1h 25min 53s, sys: 3min 9s, total: 1h 29min 2s\n",
      "Wall time: 58min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
